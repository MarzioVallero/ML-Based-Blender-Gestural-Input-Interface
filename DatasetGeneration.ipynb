{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be1d42e",
   "metadata": {},
   "source": [
    "# Dataset Generation for Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dadac9",
   "metadata": {},
   "source": [
    "First, we add all the useful dependencies for image collection and processing.  \n",
    "Be sure to be in the root directory of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1df295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import uuid\n",
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3315bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'Tensorflow/Workspace/images/capturedimages'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9de123",
   "metadata": {},
   "source": [
    "Now we define the list of gesture classes _labels_, which will be used to generate data for the model to train onto.  \n",
    "The _nImages_ variable specifies how many images of a single gesture shall be taken: the higher, the better variance you'll get in the final dataset. However, be warned that all the images for the dataset must be labeled manually, so choose wisely. We will exploit data augmentation to generate a bigger dataset with more variance, hopefully improving the final model's generalization capabilities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c6191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['LeftL'] #, 'LeftA', 'LeftO', 'LeftV', 'LeftOpenHand', 'RIndexUp', 'RIndexDown', 'RIndexLeft', 'RIndexRight', 'RIndexFront', 'RThumbBack', 'RClearC']\n",
    "nImages = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426de088",
   "metadata": {},
   "source": [
    "We define some data aumentation functions to produce multiple output images from a single input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b68a621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_shift(input_img, ratio=0.2):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return input_img\n",
    "    img = input_img.copy()\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = h*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:int(h-to_shift), :, :]\n",
    "    if ratio < 0:\n",
    "        img = img[int(-1*to_shift):, :, :]\n",
    "    img = cv2.resize(img, (w, h), cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "def horizontal_shift(input_img, ratio=0.2):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return input_img\n",
    "    img = input_img.copy()\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = w*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):, :]\n",
    "    img = cv2.resize(img, (w, h), cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "def zoom(input_img, value=0.85):\n",
    "    if value > 1 or value < 0:\n",
    "        print('Value for zoom should be less than 1 and greater than 0')\n",
    "        return input_img\n",
    "    img = input_img.copy()\n",
    "    value = random.uniform(value, 1)\n",
    "    h, w = img.shape[:2]\n",
    "    h_taken = int(value*h)\n",
    "    w_taken = int(value*w)\n",
    "    h_start = random.randint(0, h-h_taken)\n",
    "    w_start = random.randint(0, w-w_taken)\n",
    "    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    img = cv2.resize(img, (w, h), cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9a897",
   "metadata": {},
   "source": [
    "The following code box will warn you about which gesture must be performed. The delay between each frame capture is of 2 seconds, but can be freely adjusted to whatever you need.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba14767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for LeftL\n",
      "Collected\n"
     ]
    }
   ],
   "source": [
    "frame_capture_delay = 2 #seconds\n",
    "for label in labels:\n",
    "    !mkdir {'Tensorflow\\Workspace\\images\\capturedimages\\\\' + label}\n",
    "    clear_output(wait=True)\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    input()\n",
    "    time.sleep(5)\n",
    "    for imageNumber in range(nImages):\n",
    "        ret, frame = cap.read()\n",
    "        tmpUUID = format(str(uuid.uuid1()))\n",
    "        imageName = os.path.join(imagePath, label, label+'_'+f'{tmpUUID}.jpg')\n",
    "        cv2.imwrite(imageName, frame)\n",
    "        print('Collected')\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.imwrite(os.path.join(imagePath, label, label+'_vshift_'+f'{tmpUUID}.jpg'),\n",
    "                    vertical_shift(input_img=frame))\n",
    "        cv2.imwrite(os.path.join(imagePath, label, label+'_hshift_'+f'{tmpUUID}.jpg'),\n",
    "                    horizontal_shift(input_img=frame))\n",
    "        cv2.imwrite(os.path.join(imagePath, label, label+'_zoom_'+f'{tmpUUID}.jpg'),\n",
    "                    zoom(input_img=frame))\n",
    "        time.sleep(frame_capture_delay)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyWindow('frame')\n",
    "            break\n",
    "    cap.release()\n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3d108",
   "metadata": {},
   "source": [
    "At the end of this step, go into your _capturedimages_ directory.  \n",
    "Move all the images in the automatically generated sub-directories of each class together into the _capturedimages_ directory: this will simplify the labeling procedure later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
